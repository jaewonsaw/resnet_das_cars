{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6986a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82006604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"manual_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42a2dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waterfall_filename</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>channel_start</th>\n",
       "      <th>channel_end</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>uphill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensor_2024-11-24T070135-0800.h5_Start0.0_End30.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>153</td>\n",
       "      <td>79</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensor_2024-11-24T070135-0800.h5_Start30.0_End...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sensor_2024-11-24T084635-0800.h5_Start0.0_End30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sensor_2024-11-24T084635-0800.h5_Start0.0_End30.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>153</td>\n",
       "      <td>10</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sensor_2024-11-24T093235-0800.h5_Start30.0_End...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  waterfall_filename  time_start  time_end  \\\n",
       "0  sensor_2024-11-24T070135-0800.h5_Start0.0_End30.0        22.5      30.0   \n",
       "1  sensor_2024-11-24T070135-0800.h5_Start30.0_End...        30.0      40.0   \n",
       "2  sensor_2024-11-24T084635-0800.h5_Start0.0_End30.0         5.0      18.0   \n",
       "3  sensor_2024-11-24T084635-0800.h5_Start0.0_End30.0        16.5      30.0   \n",
       "4  sensor_2024-11-24T093235-0800.h5_Start30.0_End...        41.0      53.0   \n",
       "\n",
       "   channel_start  channel_end vehicle_type  uphill  \n",
       "0            153           79        large       1  \n",
       "1             79            0        large       1  \n",
       "2            153            0        small       1  \n",
       "3            153           10        large       1  \n",
       "4            153            0        small       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340db0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.uphill == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5153b59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3064c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "target_shape = (585, 153)\n",
    "for index, rows in df.iterrows():\n",
    "    f = rows[\"waterfall_filename\"]\n",
    "    label = rows[\"vehicle_type\"]\n",
    "    new_name = \"DAS_data/FBE_Sensor\"\n",
    "    f = f.replace(\"sensor\", \"\")\n",
    "    f = f.replace(\".h5\", \"\")\n",
    "    f = f.replace(\"Start\", \"\")\n",
    "    f = f.replace(\"End\", \"\")\n",
    "    f = f.replace(\"0.0_30.0\", \"0s-30s\")\n",
    "    f = f.replace(\"30.0_60.0\", \"30s-60s\")\n",
    "    f = new_name + f + \"_10-200Hz.npy\"\n",
    "    imgs.append(np.load(f)[:585, :153])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "661a1d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 585, 153)\n"
     ]
    }
   ],
   "source": [
    "imgs = np.asarray(imgs)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5fc5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, labels, transforms, noise = 1e-3):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        self.noise = noise\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.transforms(self.imgs[i]) + torch.randn(self.imgs[i].shape)*self.noise, self.labels[i])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ad4377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: \"small\", 1: \"large\"}\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == \"small\":\n",
    "        labels[i] = 0\n",
    "    elif labels[i] == \"large\":\n",
    "        labels[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00a898a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labels = np.asarray(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea2ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb56ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.Normalize((0.5, ), (0.5, )),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1654d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = imgs[5:]\n",
    "train_labels = labels[5:]\n",
    "test_imgs = imgs[:5]\n",
    "test_labels = labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70fabff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = torch.from_numpy(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f750ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 1, 585, 153])\n"
     ]
    }
   ],
   "source": [
    "train_imgs = train_imgs.reshape((36, 1, 585, 153))\n",
    "print(train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1b3cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_imgs, train_labels, transforms)\n",
    "test_ds = Dataset(test_imgs, test_labels, transforms, noise = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61277280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a44dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.layer1 = BasicBlock(32, 64, stride=2)\n",
    "        self.layer2 = BasicBlock(64, 128, stride=2)\n",
    "        self.layer3 = BasicBlock(128, 256, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd2fe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleResNet()\n",
    "out = model(torch.zeros((1, 1, 585, 153)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee856353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:21<03:14, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7544, Accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:45<03:04, 23.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5890, Accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [01:07<02:38, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.5725, Accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [01:28<02:10, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.5916, Accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [01:50<01:49, 21.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.6960, Accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [02:12<01:27, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.6848, Accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [02:35<01:06, 22.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.4943, Accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [02:58<00:44, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.5799, Accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [03:29<00:25, 25.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.5949, Accuracy: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:55<00:00, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.6387, Accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assume model is defined and called 'model'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Dummy placeholders - replace with your real dataset\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().to(device).unsqueeze(1)  # Ensure shape [B, 1]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0a18ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-83.16533673, -80.48941362, -80.82026303, ..., -86.40004322,\n",
       "         -79.86596284, -82.38288391],\n",
       "        [-81.44822938, -80.90790602, -78.95710824, ..., -85.29818789,\n",
       "         -83.51177394, -81.44601834],\n",
       "        [-83.35952402, -78.41031449, -81.84194271, ..., -86.13143581,\n",
       "         -81.52151458, -80.6781823 ],\n",
       "        ...,\n",
       "        [-77.83159733, -80.48285566, -85.15926687, ..., -86.48475857,\n",
       "         -79.98943363, -82.98869435],\n",
       "        [-80.82277576, -79.08962964, -80.26693421, ..., -86.61039554,\n",
       "         -84.07328293, -83.1402916 ],\n",
       "        [-78.30538092, -73.51581599, -77.53454542, ..., -82.98654912,\n",
       "         -80.07903555, -82.23120977]],\n",
       "\n",
       "       [[-78.18900907, -78.6662453 , -78.81660319, ..., -86.67769961,\n",
       "         -76.21459263, -81.8938268 ],\n",
       "        [-81.22421343, -82.4349877 , -81.69241862, ..., -87.19092394,\n",
       "         -74.75361206, -80.00945675],\n",
       "        [-86.12481637, -77.3260291 , -79.61768577, ..., -87.61009091,\n",
       "         -78.31058595, -83.94645948],\n",
       "        ...,\n",
       "        [-79.14953384, -80.55974333, -82.07300495, ..., -85.58067223,\n",
       "         -81.80428627, -84.26450634],\n",
       "        [-83.7568864 , -83.52280591, -81.89188808, ..., -86.35002092,\n",
       "         -82.94795645, -84.19758344],\n",
       "        [-82.46035762, -79.76065868, -79.04796799, ..., -82.89097532,\n",
       "         -81.48992471, -82.95802804]],\n",
       "\n",
       "       [[-71.54862989, -66.53412713, -72.2163864 , ..., -66.11480615,\n",
       "         -77.4063735 , -82.83066937],\n",
       "        [-69.14748537, -64.00417085, -74.59796376, ..., -64.19378985,\n",
       "         -80.45425245, -84.0605256 ],\n",
       "        [-67.31393026, -62.2308568 , -69.89469535, ..., -37.83040066,\n",
       "         -77.09267272, -82.91267588],\n",
       "        ...,\n",
       "        [-73.32082758, -70.18760553, -70.68062949, ..., -77.0846934 ,\n",
       "         -83.53933112, -81.17405704],\n",
       "        [-70.69270908, -66.49078581, -76.35017   , ..., -70.85828083,\n",
       "         -81.46696507, -81.66606275],\n",
       "        [-68.65197856, -65.39767658, -75.53565212, ..., -71.26359833,\n",
       "         -79.17246309, -84.01076612]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-64.94920914, -62.74807661, -73.8218287 , ..., -76.43199961,\n",
       "         -81.34223917, -82.23883968],\n",
       "        [-64.84592421, -62.43529457, -71.72470456, ..., -78.8240696 ,\n",
       "         -70.15723249, -79.6841268 ],\n",
       "        [-64.42855007, -61.40183342, -75.01136947, ..., -75.91340683,\n",
       "         -73.500247  , -81.60345175],\n",
       "        ...,\n",
       "        [-56.77719118, -58.68877684, -67.42408782, ..., -83.20157004,\n",
       "         -75.81111873, -82.68604182],\n",
       "        [-56.6963027 , -57.43592504, -60.61172805, ..., -80.97232699,\n",
       "         -73.36534097, -82.760056  ],\n",
       "        [-57.49846295, -42.36359498, -61.73472124, ..., -83.20488553,\n",
       "         -76.65899192, -84.27071822]],\n",
       "\n",
       "       [[-56.2577073 , -56.84302264, -65.66400719, ..., -76.29042598,\n",
       "         -79.82088963, -83.87373845],\n",
       "        [-56.41413566, -58.8244631 , -68.26762731, ..., -79.42473868,\n",
       "         -77.66365781, -83.16599734],\n",
       "        [-58.90511242, -57.05609589, -63.05015437, ..., -77.7135439 ,\n",
       "         -78.11833428, -83.36903092],\n",
       "        ...,\n",
       "        [-65.92308035, -69.30178901, -75.43267148, ..., -74.18746337,\n",
       "         -78.1255283 , -83.8127423 ],\n",
       "        [-64.18754823, -69.58833725, -73.20533148, ..., -78.83843937,\n",
       "         -78.22283566, -84.58669958],\n",
       "        [-65.25322202, -71.94949746, -73.20417798, ..., -74.96330393,\n",
       "         -78.48149898, -82.38364956]],\n",
       "\n",
       "       [[-56.2577073 , -56.84302264, -65.66400719, ..., -76.29042598,\n",
       "         -79.82088963, -83.87373845],\n",
       "        [-56.41413566, -58.8244631 , -68.26762731, ..., -79.42473868,\n",
       "         -77.66365781, -83.16599734],\n",
       "        [-58.90511242, -57.05609589, -63.05015437, ..., -77.7135439 ,\n",
       "         -78.11833428, -83.36903092],\n",
       "        ...,\n",
       "        [-65.92308035, -69.30178901, -75.43267148, ..., -74.18746337,\n",
       "         -78.1255283 , -83.8127423 ],\n",
       "        [-64.18754823, -69.58833725, -73.20533148, ..., -78.83843937,\n",
       "         -78.22283566, -84.58669958],\n",
       "        [-65.25322202, -71.94949746, -73.20417798, ..., -74.96330393,\n",
       "         -78.48149898, -82.38364956]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d96ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images.npy\", imgs)\n",
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bd9a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8835836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
